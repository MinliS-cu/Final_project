{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c5a136-e872-4846-9965-9ddc5251a0b3",
   "metadata": {},
   "source": [
    "# NYC Apartment Search\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1BYVyFBDcTywdUlanH0ysfOrNWPgl7UkqXA7NeewTzxA/edit#heading=h.bpxu7uvknnbk)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add code as you wish._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only an idea of a possible approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf11fa0-4684-4f5e-8048-0f4cc5f4f243",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f675d4b-794e-407c-aac9-b85c4a3975d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import statements needed for the project, for example:\n",
    "import math\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import json\n",
    "import pathlib\n",
    "import urllib.parse\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from pyproj import CRS, Transformer\n",
    "from shapely.ops import transform\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "import os\n",
    "from shapely.geometry import Point\n",
    "from sqlalchemy.orm import declarative_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a62277-51cf-48a2-81d2-9b2127088a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any constants you might need; some have been added for you\n",
    "\n",
    "# Where data files will be read from/written to - this should already exist\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"zipcodes\" / \"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "APP_TOKEN = \"noFU7vdLMu3RKtmWOyOqkOi2x\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/resource/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.json\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_NAME = \"Final_Project\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_URL = f\"postgres+psycopg2://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "\n",
    "crs='EPSG:4326'\n",
    "\n",
    "rent_month_dict = {}\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd67cca9-ec72-44e3-83b8-b65f1ed5bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52476a07-9bf2-4b7a-8cb7-93648bb4d303",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63b18f12-c0ce-4b9c-adc1-805703edc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_311_data(url, start, end, limit, force=False):\n",
    "\n",
    "    url_path = urllib.parse.urlparse(url).path.split('/')[-1]\n",
    "    filename = DATA_DIR / url_path\n",
    "    \n",
    "    if not DATA_DIR.exists():\n",
    "        DATA_DIR.mkdir()\n",
    "\n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading {url} to {filename}...\")\n",
    "        \n",
    "        offset = start\n",
    "        all_entries = []\n",
    "        selected_columns = [\"unique_key\", \"created_date\", \"complaint_type\", \"incident_zip\", \"location\"]\n",
    "        \n",
    "        while offset + limit <= end:  \n",
    "            total = limit+offset\n",
    "            print(f\"start from {offset} and end is {total}\")\n",
    "            soql_query = f\"{url}?$$app_token={APP_TOKEN}&$select={','.join(selected_columns)}&$limit={limit}&$offset={offset}\"\n",
    "            response = requests.get(soql_query)\n",
    "            if response.status_code == 200: \n",
    "                entries = response.json()\n",
    "                if not entries:\n",
    "                    break \n",
    "                all_entries.extend(entries)\n",
    "                offset += limit\n",
    "            else:\n",
    "                print(f\"cannot access url error code{response.status_code}\")\n",
    "                break\n",
    "        \n",
    "        \n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(all_entries, f)\n",
    "        print(f\"Done downloading {url}.\")\n",
    "\n",
    "    else:\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Current Time = {current_time} Reading from {filename}...\")\n",
    "    \n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "163c13b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_tree_data(url, force=False):\n",
    "    \n",
    "    url_path = urllib.parse.urlparse(url).path.split('/')[-1]\n",
    "    filename = DATA_DIR / url_path\n",
    "    \n",
    "    if not DATA_DIR.exists():\n",
    "        DATA_DIR.mkdir()\n",
    "\n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading {url} to {filename}...\")\n",
    "        \n",
    "        limit = 1_000_000\n",
    "        offset = 0\n",
    "        all_entries = []\n",
    "        selected_columns = [\"created_at\", \"tree_id\", \"zipcode\", \"the_geom\", \"spc_common\", \"health\", \"status\"]\n",
    "        end = 1_000_000\n",
    "        \n",
    "        while offset < end:  \n",
    "            total = limit+offset\n",
    "            print(f\"start from {offset} and total is {total}\")\n",
    "            soql_query = f\"{url}?$$app_token={APP_TOKEN}&$select={','.join(selected_columns)}&$limit={limit}&$offset={offset}\"\n",
    "            response = requests.get(soql_query)\n",
    "            if response.status_code == 200: \n",
    "                entries = response.json()\n",
    "                if not entries:\n",
    "                    break \n",
    "                all_entries.extend(entries)\n",
    "                offset += limit\n",
    "            else:\n",
    "                print(f\"cannot access url error code{response.status_code}\")\n",
    "                break\n",
    "        \n",
    "        \n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(all_entries, f)\n",
    "        print(f\"Done downloading {url}.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Reading from {filename}...\")\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee245240-2fbb-45b8-9a92-4e2368f62c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile):\n",
    "    global unique_zipcodes\n",
    "    gdf = gpd.read_file(\"data/nyc_zipcodes/nyc_zipcodes.shp\")\n",
    "    gdf = gdf.to_crs(4326)\n",
    "    zip_code = gdf[[\"ZIPCODE\", \"geometry\"]].copy()\n",
    "    unique_zipcodes_df = zip_code.drop_duplicates(subset = [\"ZIPCODE\"], keep = \"last\").reset_index()\n",
    "    unique_zipcodes = unique_zipcodes_df[\"ZIPCODE\"]\n",
    "    return unique_zipcodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eed2a5a9-1027-4c41-bbb5-039c32ce7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_311_data():\n",
    "    Service_Requests_url = f\"{BASE_NYC_DATA_URL}{NYC_DATA_311}\"\n",
    "    start = 0\n",
    "    end = 100_000_000\n",
    "    limit = 1_000_000\n",
    "    filename = download_nyc_311_data(Service_Requests_url, start, end, limit)\n",
    "    \n",
    "    interactions_geo_data_frame = gpd.GeoDataFrame(pd.read_json(filename), dtype='object')\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f\"Current Time = {current_time} reading done from {filename}...\")`\n",
    "    \n",
    "    if 'location' in interactions_geo_data_frame.columns:\n",
    "            interactions_geo_data_frame['longitude'] = interactions_geo_data_frame['location'].apply(\n",
    "                lambda loc: loc.get('longitude') if isinstance(loc, dict) else None\n",
    "            )\n",
    "            interactions_geo_data_frame['latitude'] = interactions_geo_data_frame['location'].apply(\n",
    "                lambda loc: loc.get('latitude') if isinstance(loc, dict) else None\n",
    "            )\n",
    "            \n",
    "            geometry = gpd.GeoSeries(\n",
    "                interactions_geo_data_frame.apply(\n",
    "                    lambda row: Point(float(row['longitude']), float(row['latitude'])) if not pd.isna(row['longitude']) and not pd.isna(row['latitude']) else None,\n",
    "                    axis=1\n",
    "                ),\n",
    "                crs='EPSG:4326'\n",
    "            )\n",
    "    \n",
    "    if 'location' in interactions_geo_data_frame.columns:\n",
    "        interactions_geo_data_frame.drop(columns=['location'], inplace=True)\n",
    "    if 'longitude' in interactions_geo_data_frame.columns:\n",
    "        interactions_geo_data_frame.drop(columns=['longitude'], inplace=True)\n",
    "    if 'latitude' in interactions_geo_data_frame.columns:\n",
    "        interactions_geo_data_frame.drop(columns=['latitude'], inplace=True)\n",
    "            \n",
    "    interactions_geo_data_frame.set_geometry(geometry, inplace=True)\n",
    "        \n",
    "    interactions_geo_data_frame = interactions_geo_data_frame.dropna(subset=['incident_zip'])\n",
    "    interactions_geo_data_frame = interactions_geo_data_frame[interactions_geo_data_frame[\"incident_zip\"].isin(unique_zipcodes)]\n",
    "    \n",
    "    interactions_geo_data_frame['created_date'] = pd.to_datetime(interactions_geo_data_frame['created_date'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f\"Current Time = {current_time} done\")\n",
    "    \n",
    "    #interactions_geo_df = interactions_geo_df.drop_duplicates(subset=['unique_key']).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return interactions_geo_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35db9db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_local_311_data():\n",
    "    # Directory containing the JSON files\n",
    "    json_files_directory = 'complain_data/'\n",
    "    json_files = [f\"{i}.json\" for i in range(1, 36)]\n",
    "\n",
    "    interactions_geo_data_frames = []\n",
    "\n",
    "    # Iterate through each file in the directory\n",
    "    for interactions_input_file in json_files:\n",
    "        now = datetime.now()\n",
    "\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Current Time = {current_time} input_file {interactions_input_file} begin\" )\n",
    "        file_path = os.path.join(json_files_directory, interactions_input_file)\n",
    "        interactions_geo_data_frame = gpd.GeoDataFrame(pd.read_json(file_path, dtype='object'))\n",
    "        #interactions_geo_data_frame = gpd.read_file(file_path, dtype='object')\n",
    "    \n",
    "        if 'location' in interactions_geo_data_frame.columns:\n",
    "            #if 'longitude' in interactions_geo_data_frame['location'].columns and 'latitude' in interactions_geo_data_frame['location'].columns:\n",
    "                interactions_geo_data_frame['longitude'] = interactions_geo_data_frame['location'].apply(\n",
    "                    lambda loc: loc.get('longitude') if isinstance(loc, dict) else None\n",
    "                )\n",
    "                interactions_geo_data_frame['latitude'] = interactions_geo_data_frame['location'].apply(\n",
    "                    lambda loc: loc.get('latitude') if isinstance(loc, dict) else None\n",
    "                )\n",
    "\n",
    "\n",
    "                geometry = gpd.GeoSeries(\n",
    "                    interactions_geo_data_frame.apply(\n",
    "                        lambda row: Point(float(row['longitude']), float(row['latitude'])) if not pd.isna(row['longitude']) and not pd.isna(row['latitude']) else None,\n",
    "                        axis=1\n",
    "                    ),\n",
    "                    crs='EPSG:4326'\n",
    "                )\n",
    "\n",
    "        \n",
    "\n",
    "        if 'location' in interactions_geo_data_frame.columns:\n",
    "                interactions_geo_data_frame.drop(columns=['location'], inplace=True)\n",
    "        if 'longitude' in interactions_geo_data_frame.columns:\n",
    "                interactions_geo_data_frame.drop(columns=['longitude'], inplace=True)\n",
    "        if 'latitude' in interactions_geo_data_frame.columns:\n",
    "                interactions_geo_data_frame.drop(columns=['latitude'], inplace=True)\n",
    "    \n",
    "        interactions_geo_data_frame.set_geometry(geometry, inplace=True)\n",
    "        \n",
    "        interactions_geo_data_frame = interactions_geo_data_frame.dropna(subset=['incident_zip'])\n",
    "        interactions_geo_data_frame = interactions_geo_data_frame[interactions_geo_data_frame[\"incident_zip\"].isin(unique_zipcodes)]\n",
    "\n",
    "        interactions_geo_data_frame['created_date'] = pd.to_datetime(interactions_geo_data_frame['created_date'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
    "\n",
    "        interactions_geo_data_frames.append(interactions_geo_data_frame)\n",
    "    \n",
    "    \n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f\"Current Time = {current_time} load file done\" )\n",
    "    interactions_geo_df = gpd.GeoDataFrame(pd.concat(interactions_geo_data_frames, ignore_index=True, sort=True))\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f\"Current Time = {current_time} concat file done\" )\n",
    "    interactions_geo_df.crs = interactions_geo_data_frames[0].crs\n",
    "    interactions_geo_data_frames.clear()\n",
    "    interactions_geo_df = interactions_geo_df.drop_duplicates(subset=['unique_key']).reset_index(drop=True)\n",
    "    now = datetime.now()\n",
    "\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f\"Current Time = {current_time} done normalized data 311\" )\n",
    "    \n",
    "    return interactions_geo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39c4b1bc-c841-4b87-8301-1dc2cafeccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data():\n",
    "    Trees_url = f\"{BASE_NYC_DATA_URL}{NYC_DATA_TREES}\"\n",
    "    filename = download_nyc_tree_data(Trees_url)\n",
    "    trees_gdf = gpd.GeoDataFrame(pd.read_json(filename), dtype='object')\n",
    "    convert_dict = {\n",
    "        \"tree_id\" : int,\n",
    "        \"spc_common\" :str,\n",
    "        \"health\": str,\n",
    "        \"status\": str,\n",
    "        \"the_geom\" : \"geometry\",\n",
    "        \"zipcode\":str\n",
    "    }\n",
    "    \n",
    "    trees_gdf['the_geom'] = gpd.GeoSeries(\n",
    "        trees_gdf['the_geom'].apply(lambda x: Point(x['coordinates'])), crs='EPSG:4326'\n",
    "    )\n",
    "    \n",
    "    trees_gdf_normalized = gpd.GeoDataFrame(trees_gdf.astype(convert_dict))\n",
    "    trees_gdf_normalized = gpd.GeoDataFrame(trees_gdf_normalized[trees_gdf_normalized[\"zipcode\"].isin(unique_zipcodes)])\n",
    "    \n",
    "    return trees_gdf_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "747ff49f-a18b-4fc0-8da6-6834a10d11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zillow_data(ZILLOW_DATA_FILE):\n",
    "    global rent_month_dict\n",
    "    zillow_rent_data = pd.read_csv(ZILLOW_DATA_FILE)\n",
    "    NY_rent_date = zillow_rent_data[zillow_rent_data[\"City\"] == \"New York\"]\n",
    "    NY_rent_date = NY_rent_date.reset_index(drop=True)\n",
    "    NY_rent_date_sub = NY_rent_date.drop(columns=['RegionID', 'SizeRank', 'RegionType', 'StateName', 'State','City','Metro','CountyName'])\n",
    "    column_names = NY_rent_date_sub.columns.tolist()\n",
    "    for i,j in enumerate(column_names):\n",
    "        if i > 0:\n",
    "            rent_month_dict[j] = i-1\n",
    "    return NY_rent_date_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "345ebc2c-14f1-490c-9857-11f1e332e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    print(f\"load zipcode data done\")\n",
    "    #geodf_311_data = download_and_clean_311_data()\n",
    "    geodf_311_data = load_local_311_data()\n",
    "    print(f\"load 311 data done\")\n",
    "    geodf_tree_data = download_and_clean_tree_data()\n",
    "    print(f\"load trees data done\")\n",
    "    df_zillow_data = load_and_clean_zillow_data(ZILLOW_DATA_FILE)\n",
    "    print(f\"load rents data done\")\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb740a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load zipcode data done\n",
      "Current Time = 02:04:45 Reading from data/erm2-nwe9.json...\n"
     ]
    }
   ],
   "source": [
    "# geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "# print(f\"load zipcode data done\")\n",
    "# geodf_311_data = download_and_clean_311_data()\n",
    "# print(f\"load 311 data done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "419ce18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data = load_and_clean_zillow_data(ZILLOW_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a3554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "# print(f\"load zipcode data done\")\n",
    "# geodf_tree_data = download_and_clean_tree_data()\n",
    "# print(f\"load trees data done\")\n",
    "# df_zillow_data = load_and_clean_zillow_data(ZILLOW_DATA_FILE)\n",
    "# print(f\"load rents data done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2768bc8-4130-4298-be28-13d4b250a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23ad8bbc-bf91-457e-97db-a945fabeee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 248 entries, 0 to 247\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   index     248 non-null    int64   \n",
      " 1   ZIPCODE   248 non-null    object  \n",
      " 2   geometry  248 non-null    geometry\n",
      "dtypes: geometry(1), int64(1), object(1)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Show basic info about each dataframe\n",
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec68f4be-f365-46c1-91a1-ab75deb75ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11436</td>\n",
       "      <td>POLYGON ((-73.80585 40.68291, -73.80569 40.682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11213</td>\n",
       "      <td>POLYGON ((-73.93740 40.67973, -73.93487 40.679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11212</td>\n",
       "      <td>POLYGON ((-73.90294 40.67084, -73.90223 40.668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11225</td>\n",
       "      <td>POLYGON ((-73.95797 40.67066, -73.95576 40.670...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11218</td>\n",
       "      <td>POLYGON ((-73.97208 40.65060, -73.97192 40.650...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index ZIPCODE                                           geometry\n",
       "0      0   11436  POLYGON ((-73.80585 40.68291, -73.80569 40.682...\n",
       "1      1   11213  POLYGON ((-73.93740 40.67973, -73.93487 40.679...\n",
       "2      2   11212  POLYGON ((-73.90294 40.67084, -73.90223 40.668...\n",
       "3      3   11225  POLYGON ((-73.95797 40.67066, -73.95576 40.670...\n",
       "4      4   11218  POLYGON ((-73.97208 40.65060, -73.97192 40.650..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 5 entries about each dataframe\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a803b68-2f07-44b8-8b24-d4f16c9e03fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 33233422 entries, 0 to 33233421\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   complaint_type  object        \n",
      " 1   created_date    datetime64[ns]\n",
      " 2   geometry        geometry      \n",
      " 3   incident_zip    object        \n",
      " 4   unique_key      object        \n",
      "dtypes: datetime64[ns](1), geometry(1), object(3)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14705df9-ea77-4d57-ac8e-1845f80a216d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>created_date</th>\n",
       "      <th>geometry</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>unique_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derelict Vehicles</td>\n",
       "      <td>2023-11-17 12:00:00</td>\n",
       "      <td>POINT (-73.98863 40.77506)</td>\n",
       "      <td>10069</td>\n",
       "      <td>59469711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Derelict Vehicles</td>\n",
       "      <td>2023-11-17 12:00:00</td>\n",
       "      <td>POINT (-73.90324 40.75259)</td>\n",
       "      <td>11377</td>\n",
       "      <td>59468480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Illegal Parking</td>\n",
       "      <td>2023-11-17 01:06:19</td>\n",
       "      <td>POINT (-73.97546 40.59379)</td>\n",
       "      <td>11223</td>\n",
       "      <td>59463383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rodent</td>\n",
       "      <td>2023-11-17 01:05:09</td>\n",
       "      <td>POINT (-73.86890 40.83262)</td>\n",
       "      <td>10472</td>\n",
       "      <td>59463316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-Emergency Police Matter</td>\n",
       "      <td>2023-11-17 01:03:42</td>\n",
       "      <td>POINT (-73.86991 40.74827)</td>\n",
       "      <td>11373</td>\n",
       "      <td>59462918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                complaint_type        created_date  \\\n",
       "0            Derelict Vehicles 2023-11-17 12:00:00   \n",
       "1            Derelict Vehicles 2023-11-17 12:00:00   \n",
       "2              Illegal Parking 2023-11-17 01:06:19   \n",
       "3                       Rodent 2023-11-17 01:05:09   \n",
       "4  Non-Emergency Police Matter 2023-11-17 01:03:42   \n",
       "\n",
       "                     geometry incident_zip unique_key  \n",
       "0  POINT (-73.98863 40.77506)        10069   59469711  \n",
       "1  POINT (-73.90324 40.75259)        11377   59468480  \n",
       "2  POINT (-73.97546 40.59379)        11223   59463383  \n",
       "3  POINT (-73.86890 40.83262)        10472   59463316  \n",
       "4  POINT (-73.86991 40.74827)        11373   59462918  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6006cd2-3a00-4660-8d2a-a660b9bfd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f880ef-c5fc-4159-8174-21ccd44f492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59724f74-5f1e-435c-b843-f381a875dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29ae5d9-9768-4590-a2f2-dd63b07dd712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
