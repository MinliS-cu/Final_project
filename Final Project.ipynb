{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c5a136-e872-4846-9965-9ddc5251a0b3",
   "metadata": {},
   "source": [
    "# NYC Apartment Search\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1BYVyFBDcTywdUlanH0ysfOrNWPgl7UkqXA7NeewTzxA/edit#heading=h.bpxu7uvknnbk)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add code as you wish._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only an idea of a possible approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf11fa0-4684-4f5e-8048-0f4cc5f4f243",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f675d4b-794e-407c-aac9-b85c4a3975d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import statements needed for the project, for example:\n",
    "import math\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import json\n",
    "import pathlib\n",
    "import urllib.parse\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from pyproj import CRS, Transformer\n",
    "from shapely.ops import transform\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "import os\n",
    "from shapely.geometry import Point\n",
    "from sqlalchemy.orm import declarative_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a62277-51cf-48a2-81d2-9b2127088a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any constants you might need; some have been added for you\n",
    "\n",
    "# Where data files will be read from/written to - this should already exist\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"zipcodes\" / \"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "APP_TOKEN = \"noFU7vdLMu3RKtmWOyOqkOi2x\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/resource/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.json\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_NAME = \"Final_Project\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_URL = f\"postgres+psycopg2://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "\n",
    "crs='EPSG:4326'\n",
    "\n",
    "rent_month_dict = {}\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd67cca9-ec72-44e3-83b8-b65f1ed5bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52476a07-9bf2-4b7a-8cb7-93648bb4d303",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63b18f12-c0ce-4b9c-adc1-805703edc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_311_data(url, start, end, limit, force=False):\n",
    "\n",
    "    url_path = urllib.parse.urlparse(url).path.split('/')[-1]\n",
    "    filename = DATA_DIR / url_path\n",
    "    \n",
    "    if not DATA_DIR.exists():\n",
    "        DATA_DIR.mkdir()\n",
    "\n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading {url} to {filename}...\")\n",
    "        \n",
    "        offset = start\n",
    "        all_entries = []\n",
    "        selected_columns = [\"unique_key\", \"created_date\", \"complaint_type\", \"incident_zip\", \"location\"]\n",
    "        \n",
    "        while offset + limit <= end:  \n",
    "            total = limit+offset\n",
    "            print(f\"start from {offset} and end is {total}\")\n",
    "            soql_query = f\"{url}?$$app_token={APP_TOKEN}&$select={','.join(selected_columns)}&$limit={limit}&$offset={offset}\"\n",
    "            response = requests.get(soql_query)\n",
    "            if response.status_code == 200: \n",
    "                entries = response.json()\n",
    "                if not entries:\n",
    "                    break \n",
    "                all_entries.extend(entries)\n",
    "                offset += limit\n",
    "            else:\n",
    "                print(f\"cannot access url error code{response.status_code}\")\n",
    "                break\n",
    "        \n",
    "        \n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(all_entries, f)\n",
    "        print(f\"Done downloading {url}.\")\n",
    "\n",
    "    else:\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Current Time = {current_time} Reading from {filename}...\")\n",
    "    \n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "163c13b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_tree_data(url, force=False):\n",
    "    \n",
    "    url_path = urllib.parse.urlparse(url).path.split('/')[-1]\n",
    "    filename = DATA_DIR / url_path\n",
    "    \n",
    "    if not DATA_DIR.exists():\n",
    "        DATA_DIR.mkdir()\n",
    "\n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading {url} to {filename}...\")\n",
    "        \n",
    "        limit = 1_000_000\n",
    "        offset = 0\n",
    "        all_entries = []\n",
    "        selected_columns = [\"created_at\", \"tree_id\", \"zipcode\", \"the_geom\", \"spc_common\", \"health\", \"status\"]\n",
    "        end = 1_000_000\n",
    "        \n",
    "        while offset < end:  \n",
    "            total = limit+offset\n",
    "            print(f\"start from {offset} and total is {total}\")\n",
    "            soql_query = f\"{url}?$$app_token={APP_TOKEN}&$select={','.join(selected_columns)}&$limit={limit}&$offset={offset}\"\n",
    "            response = requests.get(soql_query)\n",
    "            if response.status_code == 200: \n",
    "                entries = response.json()\n",
    "                if not entries:\n",
    "                    break \n",
    "                all_entries.extend(entries)\n",
    "                offset += limit\n",
    "            else:\n",
    "                print(f\"cannot access url error code{response.status_code}\")\n",
    "                break\n",
    "        \n",
    "        \n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(all_entries, f)\n",
    "        print(f\"Done downloading {url}.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Reading from {filename}...\")\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee245240-2fbb-45b8-9a92-4e2368f62c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile):\n",
    "    global unique_zipcodes\n",
    "    gdf = gpd.read_file(\"data/nyc_zipcodes/nyc_zipcodes.shp\")\n",
    "    gdf = gdf.to_crs(4326)\n",
    "    zip_code = gdf[[\"ZIPCODE\", \"geometry\"]].copy()\n",
    "    unique_zipcodes_df = zip_code.drop_duplicates(subset = [\"ZIPCODE\"], keep = \"last\").reset_index()\n",
    "    unique_zipcodes = unique_zipcodes_df[\"ZIPCODE\"]\n",
    "    return unique_zipcodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eed2a5a9-1027-4c41-bbb5-039c32ce7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_311_data():\n",
    "    Service_Requests_url = f\"{BASE_NYC_DATA_URL}{NYC_DATA_311}\"\n",
    "    start = 0\n",
    "    end = 100_000_000\n",
    "    limit = 1_000_000\n",
    "    filename = download_nyc_311_data(Service_Requests_url, start, end, limit)\n",
    "    \n",
    "    interactions_geo_data_frame = gpd.GeoDataFrame(pd.read_json(filename), dtype='object')\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f\"Current Time = {current_time} reading done from {filename}...\")`\n",
    "    \n",
    "    if 'location' in interactions_geo_data_frame.columns:\n",
    "            interactions_geo_data_frame['longitude'] = interactions_geo_data_frame['location'].apply(\n",
    "                lambda loc: loc.get('longitude') if isinstance(loc, dict) else None\n",
    "            )\n",
    "            interactions_geo_data_frame['latitude'] = interactions_geo_data_frame['location'].apply(\n",
    "                lambda loc: loc.get('latitude') if isinstance(loc, dict) else None\n",
    "            )\n",
    "            \n",
    "            geometry = gpd.GeoSeries(\n",
    "                interactions_geo_data_frame.apply(\n",
    "                    lambda row: Point(float(row['longitude']), float(row['latitude'])) if not pd.isna(row['longitude']) and not pd.isna(row['latitude']) else None,\n",
    "                    axis=1\n",
    "                ),\n",
    "                crs='EPSG:4326'\n",
    "            )\n",
    "    \n",
    "    if 'location' in interactions_geo_data_frame.columns:\n",
    "        interactions_geo_data_frame.drop(columns=['location'], inplace=True)\n",
    "    if 'longitude' in interactions_geo_data_frame.columns:\n",
    "        interactions_geo_data_frame.drop(columns=['longitude'], inplace=True)\n",
    "    if 'latitude' in interactions_geo_data_frame.columns:\n",
    "        interactions_geo_data_frame.drop(columns=['latitude'], inplace=True)\n",
    "            \n",
    "    interactions_geo_data_frame.set_geometry(geometry, inplace=True)\n",
    "        \n",
    "    interactions_geo_data_frame = interactions_geo_data_frame.dropna(subset=['incident_zip'])\n",
    "    interactions_geo_data_frame = interactions_geo_data_frame[interactions_geo_data_frame[\"incident_zip\"].isin(unique_zipcodes)]\n",
    "    \n",
    "    interactions_geo_data_frame['created_date'] = pd.to_datetime(interactions_geo_data_frame['created_date'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f\"Current Time = {current_time} done\")\n",
    "    \n",
    "    #interactions_geo_df = interactions_geo_df.drop_duplicates(subset=['unique_key']).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return interactions_geo_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35db9db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_local_311_data():\n",
    "    # Directory containing the JSON files\n",
    "    json_files_directory = 'complain_data/'\n",
    "    json_files = [f\"{i}.json\" for i in range(1, 36)]\n",
    "\n",
    "    interactions_geo_data_frames = []\n",
    "\n",
    "    # Iterate through each file in the directory\n",
    "    for interactions_input_file in json_files:\n",
    "        now = datetime.now()\n",
    "\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Current Time = {current_time} input_file {interactions_input_file} begin\" )\n",
    "        file_path = os.path.join(json_files_directory, interactions_input_file)\n",
    "        interactions_geo_data_frame = gpd.GeoDataFrame(pd.read_json(file_path, dtype='object'))\n",
    "        #interactions_geo_data_frame = gpd.read_file(file_path, dtype='object')\n",
    "    \n",
    "        if 'location' in interactions_geo_data_frame.columns:\n",
    "            #if 'longitude' in interactions_geo_data_frame['location'].columns and 'latitude' in interactions_geo_data_frame['location'].columns:\n",
    "                interactions_geo_data_frame['longitude'] = interactions_geo_data_frame['location'].apply(\n",
    "                    lambda loc: loc.get('longitude') if isinstance(loc, dict) else None\n",
    "                )\n",
    "                interactions_geo_data_frame['latitude'] = interactions_geo_data_frame['location'].apply(\n",
    "                    lambda loc: loc.get('latitude') if isinstance(loc, dict) else None\n",
    "                )\n",
    "\n",
    "\n",
    "                geometry = gpd.GeoSeries(\n",
    "                    interactions_geo_data_frame.apply(\n",
    "                        lambda row: Point(float(row['longitude']), float(row['latitude'])) if not pd.isna(row['longitude']) and not pd.isna(row['latitude']) else None,\n",
    "                        axis=1\n",
    "                    ),\n",
    "                    crs='EPSG:4326'\n",
    "                )\n",
    "\n",
    "        \n",
    "\n",
    "        if 'location' in interactions_geo_data_frame.columns:\n",
    "                interactions_geo_data_frame.drop(columns=['location'], inplace=True)\n",
    "        if 'longitude' in interactions_geo_data_frame.columns:\n",
    "                interactions_geo_data_frame.drop(columns=['longitude'], inplace=True)\n",
    "        if 'latitude' in interactions_geo_data_frame.columns:\n",
    "                interactions_geo_data_frame.drop(columns=['latitude'], inplace=True)\n",
    "    \n",
    "        interactions_geo_data_frame.set_geometry(geometry, inplace=True)\n",
    "        \n",
    "        interactions_geo_data_frame = interactions_geo_data_frame.dropna(subset=['incident_zip'])\n",
    "        interactions_geo_data_frame = interactions_geo_data_frame[interactions_geo_data_frame[\"incident_zip\"].isin(unique_zipcodes)]\n",
    "\n",
    "        interactions_geo_data_frame['created_date'] = pd.to_datetime(interactions_geo_data_frame['created_date'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
    "\n",
    "        interactions_geo_data_frames.append(interactions_geo_data_frame)\n",
    "    \n",
    "    \n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f\"Current Time = {current_time} load file done\" )\n",
    "    interactions_geo_df = gpd.GeoDataFrame(pd.concat(interactions_geo_data_frames, ignore_index=True, sort=True))\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f\"Current Time = {current_time} concat file done\" )\n",
    "    interactions_geo_df.crs = interactions_geo_data_frames[0].crs\n",
    "    interactions_geo_data_frames.clear()\n",
    "    interactions_geo_df = interactions_geo_df.drop_duplicates(subset=['unique_key']).reset_index(drop=True)\n",
    "    now = datetime.now()\n",
    "\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f\"Current Time = {current_time} done normalized data 311\" )\n",
    "    \n",
    "    return interactions_geo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39c4b1bc-c841-4b87-8301-1dc2cafeccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data():\n",
    "    Trees_url = f\"{BASE_NYC_DATA_URL}{NYC_DATA_TREES}\"\n",
    "    filename = download_nyc_tree_data(Trees_url)\n",
    "    trees_gdf = gpd.GeoDataFrame(pd.read_json(filename), dtype='object')\n",
    "    convert_dict = {\n",
    "        \"tree_id\" : int,\n",
    "        \"spc_common\" :str,\n",
    "        \"health\": str,\n",
    "        \"status\": str,\n",
    "        \"the_geom\" : \"geometry\",\n",
    "        \"zipcode\":str\n",
    "    }\n",
    "    \n",
    "    trees_gdf['the_geom'] = gpd.GeoSeries(\n",
    "        trees_gdf['the_geom'].apply(lambda x: Point(x['coordinates'])), crs='EPSG:4326'\n",
    "    )\n",
    "    \n",
    "    trees_gdf_normalized = gpd.GeoDataFrame(trees_gdf.astype(convert_dict))\n",
    "    trees_gdf_normalized = gpd.GeoDataFrame(trees_gdf_normalized[trees_gdf_normalized[\"zipcode\"].isin(unique_zipcodes)])\n",
    "    \n",
    "    return trees_gdf_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "747ff49f-a18b-4fc0-8da6-6834a10d11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zillow_data(ZILLOW_DATA_FILE):\n",
    "    global rent_month_dict\n",
    "    zillow_rent_data = pd.read_csv(ZILLOW_DATA_FILE)\n",
    "    NY_rent_date = zillow_rent_data[zillow_rent_data[\"City\"] == \"New York\"]\n",
    "    NY_rent_date = NY_rent_date.reset_index(drop=True)\n",
    "    NY_rent_date_sub = NY_rent_date.drop(columns=['RegionID', 'SizeRank', 'RegionType', 'StateName', 'State','City','Metro','CountyName'])\n",
    "    column_names = NY_rent_date_sub.columns.tolist()\n",
    "    for i,j in enumerate(column_names):\n",
    "        if i > 0:\n",
    "            rent_month_dict[j] = i-1\n",
    "    return NY_rent_date_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "345ebc2c-14f1-490c-9857-11f1e332e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    print(f\"load zipcode data done\")\n",
    "    #geodf_311_data = download_and_clean_311_data()\n",
    "    geodf_311_data = load_local_311_data()\n",
    "    print(f\"load 311 data done\")\n",
    "    geodf_tree_data = download_and_clean_tree_data()\n",
    "    print(f\"load trees data done\")\n",
    "    df_zillow_data = load_and_clean_zillow_data(ZILLOW_DATA_FILE)\n",
    "    print(f\"load rents data done\")\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb740a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load zipcode data done\n",
      "Current Time = 02:04:45 Reading from data/erm2-nwe9.json...\n"
     ]
    }
   ],
   "source": [
    "# geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "# print(f\"load zipcode data done\")\n",
    "# geodf_311_data = download_and_clean_311_data()\n",
    "# print(f\"load 311 data done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "419ce18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data = load_and_clean_zillow_data(ZILLOW_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a3554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "# print(f\"load zipcode data done\")\n",
    "# geodf_tree_data = download_and_clean_tree_data()\n",
    "# print(f\"load trees data done\")\n",
    "# df_zillow_data = load_and_clean_zillow_data(ZILLOW_DATA_FILE)\n",
    "# print(f\"load rents data done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2768bc8-4130-4298-be28-13d4b250a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23ad8bbc-bf91-457e-97db-a945fabeee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 248 entries, 0 to 247\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   index     248 non-null    int64   \n",
      " 1   ZIPCODE   248 non-null    object  \n",
      " 2   geometry  248 non-null    geometry\n",
      "dtypes: geometry(1), int64(1), object(1)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Show basic info about each dataframe\n",
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec68f4be-f365-46c1-91a1-ab75deb75ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11436</td>\n",
       "      <td>POLYGON ((-73.80585 40.68291, -73.80569 40.682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11213</td>\n",
       "      <td>POLYGON ((-73.93740 40.67973, -73.93487 40.679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11212</td>\n",
       "      <td>POLYGON ((-73.90294 40.67084, -73.90223 40.668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11225</td>\n",
       "      <td>POLYGON ((-73.95797 40.67066, -73.95576 40.670...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11218</td>\n",
       "      <td>POLYGON ((-73.97208 40.65060, -73.97192 40.650...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index ZIPCODE                                           geometry\n",
       "0      0   11436  POLYGON ((-73.80585 40.68291, -73.80569 40.682...\n",
       "1      1   11213  POLYGON ((-73.93740 40.67973, -73.93487 40.679...\n",
       "2      2   11212  POLYGON ((-73.90294 40.67084, -73.90223 40.668...\n",
       "3      3   11225  POLYGON ((-73.95797 40.67066, -73.95576 40.670...\n",
       "4      4   11218  POLYGON ((-73.97208 40.65060, -73.97192 40.650..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 5 entries about each dataframe\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a803b68-2f07-44b8-8b24-d4f16c9e03fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 33233422 entries, 0 to 33233421\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   complaint_type  object        \n",
      " 1   created_date    datetime64[ns]\n",
      " 2   geometry        geometry      \n",
      " 3   incident_zip    object        \n",
      " 4   unique_key      object        \n",
      "dtypes: datetime64[ns](1), geometry(1), object(3)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14705df9-ea77-4d57-ac8e-1845f80a216d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>created_date</th>\n",
       "      <th>geometry</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>unique_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derelict Vehicles</td>\n",
       "      <td>2023-11-17 12:00:00</td>\n",
       "      <td>POINT (-73.98863 40.77506)</td>\n",
       "      <td>10069</td>\n",
       "      <td>59469711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Derelict Vehicles</td>\n",
       "      <td>2023-11-17 12:00:00</td>\n",
       "      <td>POINT (-73.90324 40.75259)</td>\n",
       "      <td>11377</td>\n",
       "      <td>59468480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Illegal Parking</td>\n",
       "      <td>2023-11-17 01:06:19</td>\n",
       "      <td>POINT (-73.97546 40.59379)</td>\n",
       "      <td>11223</td>\n",
       "      <td>59463383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rodent</td>\n",
       "      <td>2023-11-17 01:05:09</td>\n",
       "      <td>POINT (-73.86890 40.83262)</td>\n",
       "      <td>10472</td>\n",
       "      <td>59463316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-Emergency Police Matter</td>\n",
       "      <td>2023-11-17 01:03:42</td>\n",
       "      <td>POINT (-73.86991 40.74827)</td>\n",
       "      <td>11373</td>\n",
       "      <td>59462918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                complaint_type        created_date  \\\n",
       "0            Derelict Vehicles 2023-11-17 12:00:00   \n",
       "1            Derelict Vehicles 2023-11-17 12:00:00   \n",
       "2              Illegal Parking 2023-11-17 01:06:19   \n",
       "3                       Rodent 2023-11-17 01:05:09   \n",
       "4  Non-Emergency Police Matter 2023-11-17 01:03:42   \n",
       "\n",
       "                     geometry incident_zip unique_key  \n",
       "0  POINT (-73.98863 40.77506)        10069   59469711  \n",
       "1  POINT (-73.90324 40.75259)        11377   59468480  \n",
       "2  POINT (-73.97546 40.59379)        11223   59463383  \n",
       "3  POINT (-73.86890 40.83262)        10472   59463316  \n",
       "4  POINT (-73.86991 40.74827)        11373   59462918  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6006cd2-3a00-4660-8d2a-a660b9bfd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f880ef-c5fc-4159-8174-21ccd44f492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59724f74-5f1e-435c-b843-f381a875dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29ae5d9-9768-4590-a2f2-dd63b07dd712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e685942c-26dc-40db-84c2-a71aa3340806",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f349fbdd-67d0-40a4-97a0-d9b8c8ec8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_new_postgis_database(username, db_name):\n",
    "    conn = psycopg2.connect(database=f\"{db_name}\",\n",
    "                        host=\"localhost\",\n",
    "                        user=f\"{username}\",\n",
    "                        password=\"Sml123321\",\n",
    "                        port=\"5432\")\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "590ed80d-7b60-484f-a123-23b673b0f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = setup_new_postgis_database(DB_USER, DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcbf5948",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a251c-f337-4b24-bb41-96ee4621a9bd",
   "metadata": {},
   "source": [
    "### Creating Tables\n",
    "\n",
    "\n",
    "These are just a couple of options to creating your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d0cc6-74b3-4d35-a454-57f647c9f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the SQL statements to create your 4 tables\n",
    "ZIPCODE_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS NYC_zipcodes\n",
    "(\n",
    "    id serial PRIMARY KEY,\n",
    "    zipcode TEXT, \n",
    "    geometry geometry(Polygon, 4326),\n",
    "    CONSTRAINT unique_zipcode UNIQUE (zipcode)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "NYC_311_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS NYC_complaints\n",
    "(\n",
    "    id INTEGER PRIMARY KEY, \n",
    "    created_date date,\n",
    "    zipcode TEXT,\n",
    "    complaint_type TEXT,\n",
    "    location geometry(Point, 4326),\n",
    "    CONSTRAINT zip_code\n",
    "        FOREIGN KEY(zipcode)\n",
    "            REFERENCES NYC_zipcodes(zipcode)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "NYC_TREE_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS NYC_trees\n",
    "(\n",
    "    id INTEGER PRIMARY KEY, \n",
    "    created_date date,\n",
    "    zipcode TEXT,\n",
    "    location geometry,\n",
    "    species TEXT,\n",
    "    health TEXT,\n",
    "    status TEXT,\n",
    "    CONSTRAINT zip_code\n",
    "        FOREIGN KEY(zipcode)\n",
    "            REFERENCES NYC_zipcodes(zipcode)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "ZILLOW_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS NYC_rents\n",
    "(\n",
    "    id serial PRIMARY KEY,\n",
    "    zipcode TEXT,\n",
    "    rents REAL[],  \n",
    "    CONSTRAINT zip_code\n",
    "        FOREIGN KEY(zipcode)\n",
    "            REFERENCES NYC_zipcodes(zipcode)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "ZIPCODE_TABLE_INDEX = \"CREATE INDEX IF NOT EXISTS zip_geo ON NYC_zipcodes USING GIST(geometry);\"\n",
    "\n",
    "COMLIANTS_TABLE_INDEX = \"CREATE INDEX IF NOT EXISTS complaints_location ON NYC_complaints USING GIST(location);\"\n",
    "\n",
    "TREES_TABLE_INDEX = \"CREATE INDEX IF NOT EXISTS tree_location ON NYC_trees USING GIST(location);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d86f6-ff6e-4bb8-8fa2-df0d4282e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DB_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(ZIPCODE_SCHEMA)\n",
    "    f.write(NYC_311_SCHEMA)\n",
    "    f.write(NYC_TREE_SCHEMA)\n",
    "    f.write(ZILLOW_SCHEMA)\n",
    "    f.write(f\"{ZIPCODE_TABLE_INDEX}\\n\")\n",
    "    f.write(f\"{COMLIANTS_TABLE_INDEX}\\n\")\n",
    "    f.write(f\"{TREES_TABLE_INDEX}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eacd37-4fd7-4768-b689-88b07d5c234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute following queries to delete tables if already exits\n",
    "# cur.execute(\"DROP TABLE IF EXISTS NYC_trees\")\n",
    "# cur.execute(\"DROP TABLE IF EXISTS NYC_complaints\")\n",
    "# cur.execute(\"DROP TABLE IF EXISTS NYC_rents\")\n",
    "# cur.execute(\"DROP TABLE IF EXISTS NYC_zipcodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac6bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the schema files to create tables\n",
    "cur.execute(ZIPCODE_SCHEMA)\n",
    "cur.execute(NYC_311_SCHEMA)\n",
    "cur.execute(NYC_TREE_SCHEMA)\n",
    "cur.execute(ZILLOW_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d72bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(ZIPCODE_TABLE_INDEX)\n",
    "cur.execute(COMLIANTS_TABLE_INDEX)\n",
    "cur.execute(TREES_TABLE_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88a50c-9528-4a5c-9a52-b96781ee8985",
   "metadata": {},
   "source": [
    "### Add Data to Database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66af67-afb8-4f0d-bb57-552972f8e4b8",
   "metadata": {},
   "source": [
    "#### Option 1: SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e37800-cd95-44b5-9c21-eb7ac2b2e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipcodes_write_to_table(geodf_zipcode_data):\n",
    "    for zipcode, geo in zip(geodf_zipcode_data['ZIPCODE'], geodf_zipcode_data['geometry'].to_wkt()): #insert into databse\n",
    "        query = '''\n",
    "            INSERT INTO  NYC_zipcodes(zipcode, geometry)\n",
    "            VALUES \n",
    "                (%s, ST_GeomFromText(%s, 4326))\n",
    "            ''' \n",
    "        cur.execute(query, (zipcode, geo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d858451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complaints_write_to_table(geodf_311_data):\n",
    "    for id_, created_date, zipcode, complaint_type, geo in zip(geodf_311_data['unique_key'], geodf_311_data['created_date'], geodf_311_data['incident_zip'], geodf_311_data['complaint_type'], geodf_311_data['geometry'].to_wkt()): #insert into databse\n",
    "        query = '''\n",
    "            INSERT INTO NYC_complaints(id, created_date, zipcode, complaint_type, location)\n",
    "            VALUES (%s, %s, %s, %s, ST_SetSRID(ST_GeomFromText(%s), 4326))\n",
    "            '''\n",
    "        cur.execute(query, (id_, created_date, zipcode, complaint_type, geo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91b22c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_write_to_table(geodf_311_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2bc99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trees_write_to_table(geodf_tree_data):\n",
    "    for id_, created_date, zipcode, specices, health, status, geo in zip(geodf_tree_data['tree_id'], geodf_tree_data['created_at'], \n",
    "                                                                         geodf_tree_data['zipcode'], geodf_tree_data['spc_common'], \n",
    "                                                                         geodf_tree_data['health'], geodf_tree_data['status'], \n",
    "                                                                         geodf_tree_data['the_geom'].to_wkt()): #insert into databse\n",
    "        query = '''\n",
    "                INSERT INTO NYC_trees(id, created_date, zipcode, species, health, status, location)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, ST_SetSRID(ST_GeomFromText(%s), 4326))\n",
    "                '''\n",
    "        cur.execute(query, (id_, created_date, zipcode, specices, health, status, geo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aacea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rents_write_to_table(df_zillow_data):\n",
    "    all_rows_data = []\n",
    "\n",
    "    for index, row in df_zillow_data.iterrows():\n",
    "        row_data = row.iloc[1:].tolist()\n",
    "        all_rows_data.append(row_data)\n",
    "    \n",
    "    for zipcode, rent in zip(df_zillow_data['RegionName'], all_rows_data): #insert into databse\n",
    "        query = '''\n",
    "                INSERT INTO  NYC_rents(zipcode, rents)\n",
    "                VALUES (%s, %s)\n",
    "                '''\n",
    "        cur.execute(query, (zipcode, rent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6223647",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablename_to_dataframe = {\n",
    "    \"zipcodes\": geodf_zipcode_data,\n",
    "    \"complaints\": geodf_311_data,\n",
    "    \"trees\": geodf_tree_data,\n",
    "    \"rents\": df_zillow_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5eb32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(tablename_to_dataframe):\n",
    "    zipcodes_write_to_table(tablename_to_dataframe['zipcodes'])\n",
    "    print(\"write zipcodes to db done\")\n",
    "    complaints_write_to_table(tablename_to_dataframe['complaints'])\n",
    "    print(\"write complaints to db done\")\n",
    "    trees_write_to_table(tablename_to_dataframe['trees'])\n",
    "    print(\"write trees to db done\")\n",
    "    rents_write_to_table(tablename_to_dataframe['rents'])\n",
    "    print(\"write rents to db done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad8f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcodes_write_to_table(geodf_zipcode_data)\n",
    "print(\"write zipcodes to db done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f982f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_write_to_table(geodf_tree_data)\n",
    "print(\"write trees to db done\")\n",
    "rents_write_to_table(df_zillow_data)\n",
    "print(\"write rents to db done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc17b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(tablename_to_dataframe)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eab3aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(248,)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the number of entries of each table\n",
    "cur.execute(\"SELECT count(*) from NYC_zipcodes\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67141d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('11213', 'POLYGON((-73.937398 40.67973,-73.934872 40.679593,')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show a sample entries of each table\n",
    "cur.execute(\"SELECT zipcode, LEFT(ST_AsText(geometry), 50) from NYC_zipcodes Limit 2\") #count the number of ratios in the database\n",
    "cur.fetchall()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56aa19a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33233422,)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SELECT count(*) from NYC_complaints\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbc0a96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(59469711, '10069', 'POINT(-73.988634 40.775065)'),\n",
       " (59468480, '11377', 'POINT(-73.903238 40.752595)')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SELECT id, zipcode, ST_AsText(location) from NYC_complaints Limit 2\") #count the number of ratios in the database\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e05ee44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(682853,)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SELECT count(*) from NYC_trees\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "888e21ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(180683, '11375', 'POINT(-73.844215 40.723092)'),\n",
       " (200540, '11357', 'POINT(-73.818679 40.794111)')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SELECT id, zipcode, ST_AsText(location) from NYC_trees Limit 2\") #count the number of ratios in the database\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f639cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(145,)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SELECT count(*) from NYC_rents\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a12e579c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " '11208',\n",
       " 'NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, 2334.735, 2372.3096, 2408.2073, 2451.158, 2473.9316, 2498.065, 2479.6006, 2487.125, 2504.0781, 2508.6704, 2588.0303, 2613.7908, 2585.5613, 2633.2007, 2672.0386, 2806.9187, 2765.2244, 2737.5474, 2728.7334')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SELECT id, zipcode, array_to_string(rents, ', ') AS rent FROM NYC_rents;\") #count the number of ratios in the database\n",
    "cur.fetchall()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a15f3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
